{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gesture Classification with Ensemble Methods using Optical Flow\n",
    "\n",
    "Exploring ensemble methods, feature engineering, and implementing in a live system.\n",
    "\n",
    "** Junbo Huang **<br>\n",
    "juhuang@uos.de\n",
    "\n",
    "** Justin Shenk ** <br>jshenk@uos.de\n",
    "\n",
    "**Marie Sindermann**<br>msindermann@uos.de\n",
    "\n",
    "**Katie Le**<br>\n",
    "\n",
    "Follow along: https://github.com/JustinShenk/sonic-face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg') # For displaying animation\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "from sklearn import svm as svm\n",
    "from sklearn.externals import joblib\n",
    "from sklearn import linear_model as lm\n",
    "from sklearn import preprocessing as pp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier as mlpc\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.ensemble import (RandomForestClassifier, ExtraTreesClassifier, \n",
    "                              AdaBoostClassifier, BaggingClassifier, \n",
    "                              GradientBoostingClassifier)\n",
    "from helper_functions import *\n",
    "from normalize_data import *\n",
    "from numpy import array\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Motion Data\n",
    "\n",
    "Data is in x and y coordinates for each pixel. Each sample will be an array of 10 (frames) x 40 x 40 (capture window) x 2 (x and y) dimensions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load raw data for preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RAW_DATA_DIR = 'sonic_pi_face/data/'\n",
    "\n",
    "# Get list of data files\n",
    "data_files = get_data_files(RAW_DATA_DIR)\n",
    "\n",
    "# Load data into a dictionary\n",
    "# Note: Checks for incomplete data\n",
    "data_dict = get_gesture_data(data_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize optical flow (Optional)\n",
    "\n",
    "Computation of optical flow can be obtained for pixel $I(x,y,t)$ by\n",
    "$$ f_x{u} + f_y{v} + f_t = 0 $$\n",
    "\n",
    "where:\n",
    "\n",
    "$$ f_x = \\frac{\\partial f}{\\partial x} \\; ; \\; f_y = \\frac{\\partial f}{\\partial y} $$\n",
    "$$ u = \\frac{dx}{dt} \\; ; \\; v = \\frac{dy}{dt} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show individual frame (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gestures = list(data_dict)\n",
    "print(gestures) # List gestures\n",
    "sample = data_dict['open-close'][3] # 3rd Open-close sample\n",
    "image = sample[4] # 5th frame of sample\n",
    "# plt.imshow(image)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show horizontal motion across frames (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample = data_dict['open-close'][5] # Fifth sample\n",
    "# anim = display_frames(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Find features that increase the sample classification.\n",
    "\n",
    "### WIP - Histogram of Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.asarray(data_dict['slide-horizontally']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# FIXME: Complete HoG feature selection\n",
    "import matplotlib.mlab as mlab\n",
    "%matplotlib inline\n",
    "data_slide_v = np.asarray(data_dict['slide-vertically'])\n",
    "x_values = data_slide_v[:,4,...,0].flatten()\n",
    "y_values = data_slide_v[:,4,...,1].flatten()\n",
    "data_slide_h = np.asarray(data_dict['slide-horizontally'])\n",
    "x_values_h = data_slide_h[:,4,...,0].flatten()\n",
    "y_values_h = data_slide_h[:4,...,1].flatten()\n",
    "\n",
    "fig, axarr = plt.subplots(2,2)\n",
    "axarr[0,0].set_title('Horizontal motion in slide-vertical')\n",
    "axarr[0,0].hist(x_values, bins=50, normed=True)\n",
    "axarr[0,0].set_autoscaley_on(False)\n",
    "axarr[0,0].set_ylim([0,1])\n",
    "\n",
    "axarr[0,1].set_title('Vertical motion in slide-vertical')\n",
    "axarr[0,1].hist(y_values, bins=50, normed=True,orientation='horizontal')\n",
    "axarr[0,1].set_autoscalex_on(False)\n",
    "axarr[0,1].set_xlim([0,.3])\n",
    "\n",
    "axarr[1,0].set_title('Horizontal motion in slide-horizontal')\n",
    "axarr[1,0].hist(x_values_h,bins=50,normed=True)\n",
    "axarr[1,0].set_autoscaley_on(False)\n",
    "axarr[1,0].set_ylim([0,1])\n",
    "\n",
    "\n",
    "axarr[1,1].set_title('Vertical motion in slide-horizontal')\n",
    "axarr[1,1].hist(y_values_h, bins=50,normed=True, orientation='horizontal')\n",
    "axarr[1,1].set_autoscalex_on(False)\n",
    "axarr[1,1].set_xlim([0,.3])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load all pre-processed data sets if available.\n",
    "data_sets = []\n",
    "DATA_DIR = 'data'\n",
    "\n",
    "# Number of rows and colums to permute for optical flow feature extraction\n",
    "divs=[4,10,20]\n",
    "\n",
    "if os.path.exists(DATA_DIR):\n",
    "    for file in os.listdir(DATA_DIR):\n",
    "        if file.endswith('.csv'):\n",
    "            df = pd.read_csv(os.path.join(DATA_DIR,file))\n",
    "            df = df.drop('Unnamed: 0',axis=1)\n",
    "            data_sets.append(df)\n",
    "else:\n",
    "    # Generate data sets.\n",
    "    print(\"Directory not found at {}\\nPreprocessing data for \"\n",
    "        \"optimization.\".format(os.path.join(os.getcwd(),DATA_DIR)))\n",
    "    data_sets = make_feature_sets(data_dict,divs=divs)\n",
    "    # Save locally\n",
    "    save_data_sets(data_sets,divs=divs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature reduction with integral image (Optional)\n",
    "\n",
    "Integral image for fast feature evaluation.\n",
    "\n",
    "#### Use random forests for comparing feature reduction levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Example: Reduce the features of one data set.\n",
    "# Dataframe with 32 (16 * 2 (x and y coordinates)) dimensions\n",
    "df_red = feature_extract(data_dict,cols=4,rows=4)\n",
    "\n",
    "# Display comparison of feature reduction levels.\n",
    "%matplotlib inline\n",
    "gestures = ['slide-vertically','waving-beauty-pageant-style','empty']\n",
    "ax = optimize_feature_dimensions(data_sets,divs,method='rf', gestures=gestures)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parameter Optimization with Random Search (Optional)\n",
    "\n",
    "Initialize random search module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist = {\"max_depth\": [None],\n",
    "              \"max_features\": sp_randint(5, 25),\n",
    "              \"min_samples_split\": sp_randint(2, 11),\n",
    "              \"min_samples_leaf\": sp_randint(1, 11),\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# run randomized search\n",
    "n_iter_search = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "# List of gestures\n",
    "gestures=['empty','waving-beauty-pageant-style','slide-vertically']\n",
    "\n",
    "# Reduced features data set (pandas DataFrame)\n",
    "data = data_sets[1] # Choose middle (or here argmax) feature set\n",
    "data = data[data['label'].isin(gestures)]\n",
    "data, targets = encode_target(data, 'label') # Encode target column\n",
    "\n",
    "#-------------# \n",
    "# Raw data analysis for comparison (numpy array)\n",
    "empty_array = np.asarray(data_dict['empty'])\n",
    "slide_v_array = np.asarray(data_dict['slide-vertically'])\n",
    "waving_array = np.asarray(data_dict['waving-beauty-pageant-style'])\n",
    "data_raw = np.concatenate([empty_array,slide_v_array,waving_array])\n",
    "#-------------#\n",
    "\n",
    "# Split into features and target\n",
    "X, y = class_split(data,gestures=gestures)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Split into features and target (numpy raw data)\n",
    "X_raw, y_raw = class_split(data,gestures=gestures)\n",
    "X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(X_raw, y_raw, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiclass Random Forest Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Classify test data using random forest\n",
    "clf = RandomForestClassifier(n_estimators=10)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "accuracy = clf.score(X_test,y_test)\n",
    "\n",
    "print(\"Predictions:\\n{}\".format(clf.predict(X_test)))\n",
    "print(\"Actual:\\n{}\".format(y_test[:10]))\n",
    "print(\"Score:\\n{}\".format(accuracy))\n",
    "\n",
    "#FIXME\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search)\n",
    "\n",
    "random_search.fit(X.values, y.values)\n",
    "print(\"RandomizedSearchCV evaluated %d candidates\"\n",
    "      \" parameter settings.\" % (n_iter_search))\n",
    "report(random_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare raw data random forest classification (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Classify test data using random forest on raw data (optional)\n",
    "clf = RandomForestClassifier(n_estimators=10)\n",
    "clf = clf.fit(X_train_raw, y_train_raw)\n",
    "accuracy = clf.score(X_test_raw,y_test_raw)\n",
    "\n",
    "print(\"Predictions:\\n{}\".format(clf.predict(X_test_raw)))\n",
    "print(\"Actual:\\n{}\".format(y_test_raw[:10]))\n",
    "print(\"Score:\\n{}\".format(accuracy))\n",
    "\n",
    "#FIXME\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search)\n",
    "\n",
    "random_search.fit(X_raw.values, y_raw.values)\n",
    "print(\"RandomizedSearchCV evaluated %d candidates\"\n",
    "      \" parameter settings.\" % (n_iter_search))\n",
    "report(random_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_adaboost = AdaBoostClassifier(DecisionTreeClassifier())\n",
    "clf_adaboost = clf_adaboost.fit(X_train, y_train)\n",
    "accuracy = clf_adaboost.score(X_test, y_test)\n",
    "print(\"Predictions:\\n{}\".format(clf_adaboost.predict(X_test)))\n",
    "print(\"Actual:\\n{}\".format(y_test[:10]))\n",
    "print(\"Score:\\n{}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_bagging = BaggingClassifier()\n",
    "clf_bagging = clf_bagging.fit(X_train, y_train)\n",
    "print(clf_bagging.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_extra_tree = ExtraTreesClassifier()\n",
    "clf_extra_tree = clf_extra_tree.fit(X_train, y_train)\n",
    "print(clf_extra_tree.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_gradient_boosting = GradientBoostingClassifier(n_estimators=100)\n",
    "clf_gradient_boosting = clf_gradient_boosting.fit(X_train, y_train)\n",
    "print(clf_gradient_boosting.score(X_test,y_test))\n",
    "# print(\"Predictions:\\n{}\".format(clf_bagging.predict(X_test)))\n",
    "# print(\"Actual:\\n{}\".format(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_mlpc = mlpc(hidden_layer_sizes=800,verbose=True)\n",
    "clf_mlpc = clf_mlpc.fit(X_train, y_train)\n",
    "print(clf_mlpc.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_svm = svm.SVC(kernel='poly', C=1.0)\n",
    "clf_svm = clf_svm.fit(X_train, y_train)\n",
    "print(clf_svm.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save weights for best ensemble method for offline use (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joblib.dump(clf_gradient_boosting, 'classifier.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison with Hyper-Parameter Optimazation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# specify parameters and distributions to sample from\n",
    "param_dist_rf = {\n",
    "              \"max_depth\": [None],\n",
    "              \"max_features\": sp_randint(25, 32),\n",
    "              \"min_samples_split\": sp_randint(2,11),\n",
    "              \"min_samples_leaf\": sp_randint(1, 11),\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# run randomized search\n",
    "n_iter_search_rf = 100\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist_adb = {\n",
    "              \"n_estimators\": [25, 30,35,40,45,50,55,60],\n",
    "              \"learning_rate\": [0.1,0.2,0.3,0.4,0.5],\n",
    "              \"algorithm\": [\"SAMME\", \"SAMME.R\"]}\n",
    "n_iter_search_adb = 80\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist_bagging = {\"n_estimators\" : [5,10,15,20],\n",
    "              \"max_samples\" :[0.7,0.8,0.9,1.0],\n",
    "              \"max_features\" :[0.7,0.8,0.9,1.0],\n",
    "              \"bootstrap\": [True, False]\n",
    "             }\n",
    "# run randomized search\n",
    "n_iter_search_bagging = 50\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist_extree = {\"max_depth\": [None],\n",
    "              \"max_features\": sp_randint(5, 25),\n",
    "              \"min_samples_split\": sp_randint(2,11),\n",
    "              \"min_samples_leaf\": sp_randint(1, 11),\n",
    "              \"bootstrap\": [True, False]}\n",
    "             \n",
    "# run randomized search\n",
    "n_iter_search_extree = 400\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist_grab = {\"learning_rate\" : [0.1,0.2,0.3],\n",
    "              \"max_depth\": [None],\n",
    "              \"max_features\": sp_randint(5, 25),\n",
    "              \"min_samples_split\": sp_randint(2,11),\n",
    "              \"min_samples_leaf\": sp_randint(1, 11)\n",
    "              \n",
    "             }\n",
    "# run randomized search\n",
    "n_iter_search_grab = 30\n",
    "\n",
    "\n",
    "param_dist = [param_dist_rf,param_dist_adb,param_dist_bagging,\n",
    "              param_dist_extree,param_dist_grab]\n",
    "\n",
    "n_iter_search = [n_iter_search_rf,n_iter_search_adb,n_iter_search_bagging,\n",
    "                 n_iter_search_extree,n_iter_search_grab]\n",
    "models = [\n",
    "          RandomForestClassifier(),\n",
    "          AdaBoostClassifier(DecisionTreeClassifier()),\n",
    "          BaggingClassifier(),\n",
    "          ExtraTreesClassifier(),\n",
    "          GradientBoostingClassifier()\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_list = get_data_list(divs=[4,10,20])\n",
    "divs=[4,10,20]\n",
    "combis = get_combis(divs)\n",
    "\n",
    "models = [\n",
    "          RandomForestClassifier(),\n",
    "          AdaBoostClassifier(DecisionTreeClassifier()),\n",
    "          BaggingClassifier(),\n",
    "          ExtraTreesClassifier(),\n",
    "          GradientBoostingClassifier(),\n",
    "          ]\n",
    "\n",
    "for index in range(len(models)):\n",
    "        # Train models\n",
    "        random_search = RandomizedSearchCV(models[index], param_distributions=param_dist[index],\n",
    "                                   n_iter=n_iter_search[index])\n",
    "        random_search.fit(X_train, y_train)\n",
    "        #print(\"RandomizedSearchCV evaluated %d candidates\"\n",
    "        #      \" parameter settings.\" % (n_iter_search))\n",
    "\n",
    "        scores = random_search.score(X_test, y_test)\n",
    "        # Create a title for each column and the console by using str() and\n",
    "        # slicing away useless parts of the string\n",
    "        model_title = str(type(models[index])).split(\".\")[-1][:-2][:-len(\"Classifier\")]    \n",
    "        print(\"best score for {} is {}, \\n    with the parameters {}\\n\".format(model_title, random_search.best_score_,random_search.best_params_))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
