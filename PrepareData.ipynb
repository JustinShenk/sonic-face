{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gesture Classification with Ensemble Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg') # For displaying animation\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.neural_network import MLPClassifier as mlpc\n",
    "from sklearn import linear_model as lm\n",
    "from sklearn import svm as svm\n",
    "from helper_functions import *\n",
    "from normalize_data import *\n",
    "from numpy import array\n",
    "from sklearn import preprocessing as pp\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, BaggingClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Motion Data\n",
    "\n",
    "Data is in x and y coordinates for each pixel. Each sample will be an array of 10 (frames) x 40 x 40 (capture window) x 2 (x and y) dimensions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load raw data for preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RAW_DATA_DIR = 'sonic_pi_face/data/'\n",
    "\n",
    "# Get list of data files\n",
    "data_files = get_data_files(RAW_DATA_DIR)\n",
    "\n",
    "# Load data into a dictionary\n",
    "# Note: Checks for incomplete data\n",
    "data_dict = get_gesture_data(data_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize optical flow (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize individual frame (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gestures = list(data_dict)\n",
    "print(gestures) # List gestures\n",
    "sample = data_dict['open-close'][3] # 3rd Open-close sample\n",
    "image = sample[4] # 5th frame of sample\n",
    "# plt.imshow(image)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize horizontal motion across frames (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample = data_dict['open-close'][5] # Fifth sample\n",
    "# anim = display_frames(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Find features that increase the sample classification.\n",
    "\n",
    "### WIP - Histogram of Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# FIXME: Complete HoG feature selection\n",
    "data_open_close = np.asarray(data_dict['open-close'])\n",
    "x_values = data_open_close[...,0].flatten()\n",
    "y_values = data_open_close[...,1].flatten()\n",
    "plt.hist(x_values,bins=20, normed=True)\n",
    "plt.subplots()\n",
    "plt.hist(y_values,bins=20, normed=True)\n",
    "data_empty = np.asarray(data_dict['empty'])\n",
    "x_values = data_empty[...,0].flatten()\n",
    "y_values = data_empty[...,1].flatten()\n",
    "plt.subplots()\n",
    "plt.hist(x_values,bins=20,normed=True)\n",
    "plt.subplots()\n",
    "plt.hist(y_values,bins=20,normed=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load all pre-processed data sets if available.\n",
    "data_sets = []\n",
    "DATA_DIR = 'data'\n",
    "\n",
    "# Number of rows and colums to permute for optical flow feature extraction\n",
    "divs=[4,10,20]\n",
    "\n",
    "if os.path.exists(DATA_DIR):\n",
    "    for file in os.listdir(DATA_DIR):\n",
    "        if file.endswith('.csv'):\n",
    "            df = pd.read_csv(os.path.join(DATA_DIR,file))\n",
    "            df = df.drop('Unnamed: 0',axis=1)\n",
    "            data_sets.append(df)\n",
    "else:\n",
    "    # Generate data sets.\n",
    "    print(\"Directory not found at {}\\nPreprocessing data for \"\n",
    "        \"optimization.\".format(os.path.join(os.getcwd(),DATA_DIR)))\n",
    "    data_sets = make_feature_sets(data_dict,divs=divs)\n",
    "    save_data_sets(data_sets,divs=divs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature reduction with integral image\n",
    "\n",
    "Integral image for fast feature evaluation.\n",
    "\n",
    "#### Use random forests for comparing feature reduction levels. (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Example: Reduce the features of one data set.\n",
    "# Dataframe with 32 (16 * 2 (x and y coordinates)) dimensions\n",
    "df_red = feature_extract(data_dict,cols=4,rows=4)\n",
    "\n",
    "# Display comparison of feature reduction levels.\n",
    "%matplotlib inline\n",
    "ax = optimize_feature_dimensions(data_sets,divs,method='rf') # also use method='ada'\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-parameter Optimization with Random Search\n",
    "\n",
    "Initialize random search module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist = {\"max_depth\": [3, None],\n",
    "              \"max_features\": sp_randint(5, 25),\n",
    "              \"min_samples_split\": sp_randint(2, 11),\n",
    "              \"min_samples_leaf\": sp_randint(1, 11),\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# run randomized search\n",
    "n_iter_search = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "data = data_sets[0] # Choose middle (or argmax) feature set\n",
    "gestures=['open-close','empty','waving-beauty-pageant-style']\n",
    "\n",
    "# Pandas dataframe `data`\n",
    "data = data[data['label'].isin(gestures)]\n",
    "data.head()\n",
    "data, targets = encode_target(data, 'label') # Encode target column\n",
    "\n",
    "# Split into features and target\n",
    "X, y = class_split(data,gestures=gestures)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiclass Random Forest Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Classify test data using random forest\n",
    "clf = RandomForestClassifier(n_estimators=10)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "accuracy = clf.score(X_test,y_test)\n",
    "\n",
    "print(\"Predictions:\\n{}\".format(clf.predict(X_test)))\n",
    "print(\"Actual:\\n{}\".format(y_test[:10]))\n",
    "print(\"Score:\\n{}\".format(accuracy))\n",
    "\n",
    "#FIXME\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search)\n",
    "\n",
    "random_search.fit(X.values, y.values)\n",
    "print(\"RandomizedSearchCV evaluated %d candidates\"\n",
    "      \" parameter settings.\" % (n_iter_search))\n",
    "report(random_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_adaboost = AdaBoostClassifier(DecisionTreeClassifier(\n",
    "        max_depth=3), n_estimators=10)\n",
    "clf_adaboost = clf_adaboost.fit(X_train, y_train)\n",
    "accuracy = clf_adaboost.score(X_test, y_test)\n",
    "print(\"Predictions:\\n{}\".format(clf_adaboost.predict(X_test)))\n",
    "print(\"Actual:\\n{}\".format(y_test[:10]))\n",
    "print(\"Score:\\n{}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_bagging = BaggingClassifier()\n",
    "clf_bagging = clf_bagging.fit(X_train, y_train)\n",
    "print(clf_bagging.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_extra_tree = ExtraTreesClassifier()\n",
    "clf_extra_tree = clf_extra_tree.fit(X_train, y_train)\n",
    "print(clf_extra_tree.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_gradient_boosting = GradientBoostingClassifier()\n",
    "clf_gradient_boosting = clf_gradient_boosting.fit(X_train, y_train)\n",
    "print(clf_gradient_boosting.score(X_test,y_test))\n",
    "# print(\"Predictions:\\n{}\".format(clf_bagging.predict(X_test)))\n",
    "# print(\"Actual:\\n{}\".format(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_mlpc = mlpc()\n",
    "clf_mlpc = clf_mlpc.fit(X_train, y_train)\n",
    "print(clf_mlpc.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_svm = svm.SVC(decision_function_shape='ovo')\n",
    "clf_svm = clf_svm.fit(X_train, y_train)\n",
    "print(clf_svm.score(X_test,y_test))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
